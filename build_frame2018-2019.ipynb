{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext cudf.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge 2020 year frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('./data3/es/2020_new_base.xlsx')\n",
    "df2 = pd.read_excel('./data3/es/2020_old_base.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns==df2.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_rows = pd.merge(df2, df1, how='inner')\n",
    "common_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.concat([df1, df2],ignore_index=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_excel('./data3/es/2020.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018 = pd.read_excel('./data3/es/2018.xlsx')\n",
    "df2019 = pd.read_excel('./data3/es/2019.xlsx')\n",
    "df2020 = pd.read_excel('./data3/es/2020.xlsx')\n",
    "df2021 = pd.read_excel('./data3/es/2021.xlsx')\n",
    "\n",
    "df2022_23 = pd.read_csv('./data3/predict/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df2018.shape)\n",
    "print(df2019.shape)\n",
    "print(df2020.shape)\n",
    "print(df2021.shape)\n",
    "print(df2018.shape[0]+df2019.shape[0]+df2020.shape[0]+df2021.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data for training description\n",
    "Модель будет построена для предсказания значений в следующем году на основе полных данных за предыдущий год\n",
    "\n",
    "Т.е:\n",
    "\n",
    "Так как даные TR есть только начиная с 2018 года, решено отказаться от даных ранее 2018.\n",
    "Тренировочные датасеты строятся следующим образом:\n",
    "\n",
    "2018 -predict-> 2019\n",
    "\n",
    "2019 -predict-> 2020\n",
    "\n",
    "2020 -predict-> 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_23_col = df2022_23.columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_23.columns = ['code_discription', 'address_raw', 'data_short', 'cost']\n",
    "df2022_23['test']=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_same_values(col_name):\n",
    "    print(\"check column: \", col_name)\n",
    "    df2022_23_addr = df2022_23[col_name].unique()\n",
    "    df2021_addr = df2021[col_name].unique()\n",
    "    df2020_addr = df2020[col_name].unique()\n",
    "    df2019_addr = df2019[col_name].unique()\n",
    "    df2018_addr = df2018[col_name].unique()\n",
    "    print(\"unique names:\")\n",
    "    print(\"2022_23: \",len(df2022_23_addr))    \n",
    "    print(\"2021: \",len(df2021_addr))\n",
    "    print(\"2020: \",len(df2020_addr))\n",
    "    print(\"2019: \",len(df2019_addr))\n",
    "    print(\"2018: \",len(df2018_addr))\n",
    "    print(\"unique names cross\")\n",
    "    print(\"2018 vs 2019 \",len(list(set(df2018_addr) & set(df2019_addr))))\n",
    "    print(\"2019 vs 2020 \",len(list(set(df2019_addr) & set(df2020_addr))))\n",
    "    print(\"2020 vs 2021 \",len(list(set(df2020_addr) & set(df2021_addr))))\n",
    "    print(\"2022-23 vs 2021 \",len(list(set(df2022_23_addr) & set(df2021_addr))))\n",
    "    print(\"2022-23 vs 2020 \",len(list(set(df2022_23_addr) & set(df2020_addr))))\n",
    "    print(\"2022-23 vs 2019 \",len(list(set(df2022_23_addr) & set(df2019_addr))))\n",
    "    print(\"2022-23 vs 2018 \",len(list(set(df2022_23_addr) & set(df2018_addr))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_same_values('code_discription')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_same_values('address_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_same_values('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_23['code_discription'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_es_types = {1:['Электроэнергия','Оплата потребления электроэнергии','Расходы по оплате потребления электроэнергии','Оплата за дизельное топливо','Оплата за электроэнергию по тарифам','Оплата за эектроэнергию по тарифам','Плата за технологическое присоединение к электрическим сетям (в случаях, не связанным со строительством,реконстр. и кап.ремонтом'],\n",
    "            2:['Отопление','Оплата всех видов отопления зданий и сооружений (кроме электро- и газового снабжения)','Расходы по оплате всех видов отопления зданий и сооружений (кроме электро- и газового снабжения)','Оплата за тепловую энергию по тарифам','Оплата за прочие виды топлиа (уголь, дрова и т.д.)'],\n",
    "            3:['Водоснабжение','Оплата услуг водоснабжения, водоотведения','Расходы по оплате услуг водоснабжения, водоотведения','Оплата за водоотведение по тарифам','Оплата за горячее водоснабжение по тарифам','Оплата за холодное водоснабжение по тарифам', 'Оплата за холодное водоснабжение  по тарифам','Оплата за горячее  водоснабжение по тарифам','Оплата водоотведения по тарифам'],\n",
    "            4:['Коммунальные услуги (расходы прошлых лет)','Коммунальные услуги (расходы прошлых лет)','Расходы на коммунальные услуги (расходы прошлых лет)','Другие расходы прошлых лет, выявленные в текущем году.','Другие расходы прошлых лет, выявленные в текущем году.'],\n",
    "            5:['Газ','Оплата потребления газа','Расходы по оплате потребления газа','Оплата потребления газа по тарифам']}\n",
    "\n",
    "def get_type_of_es(row):\n",
    "    values_to_check = row[['code_discription', 'address_raw']]\n",
    "    for key, values in all_es_types.items():\n",
    "        if any(value.lower() in ' '.join(values_to_check.values).lower() for value in values):\n",
    "            return key\n",
    "    return None\n",
    "\n",
    "#Usage: df['es_code_int'] = df.apply(get_type_of_es, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_23['es_code_int'] = df2022_23.apply(get_type_of_es, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2021['code_discription'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2020['code_discription'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df2018['address_raw']:\n",
    "    if not ('Оплата за водоотведение по тарифам' in i or 'топливо ' in i or 'Оплата за горячее водоснабжение по тарифам' in i or 'Оплата за тепловую энергию по тарифам' in i or 'Оплата за холодное водоснабжение по тарифам'in i or 'Оплата за электроэнергию по тарифам'in i or 'Оплата за холодное водоснабжение  по тарифам' in i or 'Оплата за горячее  водоснабжение по тарифам' in i or 'Оплата за эектроэнергию по тарифам'in i\n",
    "            or 'Оплата водоотведения по тарифам'in i or 'Другие расходы прошлых лет, выявленные в текущем году.' in i or 'Оплата потребления газа по тарифам'in i or 'Плата за технологическое присоединение к электрическим сетям (в случаях, не связанным со строительством,реконстр. и кап.ремонтом' in i or 'Оплата за прочие виды топлиа (уголь, дрова и т.д.)' in i):\n",
    "        print(i)\n",
    "\n",
    "for i in df2019['address_raw']:\n",
    "    if not ('Оплата за водоотведение по тарифам' in i or 'топливо ' in i or 'Оплата за горячее водоснабжение по тарифам' in i or 'Оплата за тепловую энергию по тарифам' in i or 'Оплата за холодное водоснабжение по тарифам'in i or 'Оплата за электроэнергию по тарифам'in i or 'Оплата за холодное водоснабжение  по тарифам' in i or 'Оплата за горячее  водоснабжение по тарифам' in i or 'Оплата за эектроэнергию по тарифам'in i\n",
    "            or 'Оплата водоотведения по тарифам'in i or 'Другие расходы прошлых лет, выявленные в текущем году.' in i or 'Оплата потребления газа по тарифам'in i or 'Плата за технологическое присоединение к электрическим сетям (в случаях, не связанным со строительством,реконстр. и кап.ремонтом' in i or 'Оплата за прочие виды топлиа (уголь, дрова и т.д.)' in i):\n",
    "        print(i)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2022_23.code_discription.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_same_values('address_raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_same_values('es_code_int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prep functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append clean addr\n",
    "import re\n",
    "def to_lower(listin):\n",
    "    return [str(element).lower() for element in listin]\n",
    "\n",
    "citys = pd.read_excel('./extra/np-dvfo.xlsx', header=None)[0].to_list()\n",
    "streets = pd.read_excel('./extra/names-dvfo.xlsx', header=None)[0].to_list()\n",
    "numbers = [str(i) for i in range(1, 1000)]\n",
    "citys = to_lower(citys)\n",
    "streets = to_lower(streets)\n",
    "numbers = to_lower(numbers)\n",
    "\n",
    "def clean_address(df, addr_col, new_addr_col):\n",
    "    df[addr_col] = df[addr_col].str.lower()\n",
    "    df[new_addr_col]=df[addr_col]\n",
    "    df[new_addr_col] = df[new_addr_col].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "    df[new_addr_col] = df[new_addr_col].apply(lambda x: ' '.join(word for word in x.split() if word in citys or word in streets or word in numbers))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fuzzy compare address\n",
    "from collections import Counter\n",
    "from thefuzz import fuzz\n",
    "\n",
    "def count_same_digits(array1, array2):\n",
    "    if (len(array1)+len(array2))<2:\n",
    "        return 0\n",
    "    counter1 = Counter(array1)\n",
    "    counter2 = Counter(array2)\n",
    "    # Find the intersection considering duplicates\n",
    "    common_elements = counter1 & counter2\n",
    "\n",
    "    # Calculate the total count of common elements considering duplicates\n",
    "    count_of_common_elements = sum(common_elements.values())\n",
    "    #print(count_of_common_elements, len(array1), len(array2))\n",
    "    \n",
    "    return 2*count_of_common_elements/(len(array1)+len(array2))\n",
    "\n",
    "def spec_match(str1, str2):\n",
    "    digits_str1 = [int(d) for d in re.findall(r'\\d+', str1)]\n",
    "    digits_str2 = [int(d) for d in re.findall(r'\\d+', str2)]\n",
    "    dist = fuzz.WRatio(re.sub(r'\\d', '', str1), re.sub(r'\\d', '', str2))\n",
    "    return dist*count_same_digits(digits_str1, digits_str2)/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### append data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2019[['code_discription', 'address_raw', 'data_short', 'cost']].copy()\n",
    "df2 = df2018.copy()\n",
    "df['address_raw'] = df['address_raw'].str.lower()\n",
    "df2['address_raw'] = df2['address_raw'].str.lower()\n",
    "set(df['address_raw'])&set(df2['address_raw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['data_short']=df2['data_short'].astype(str)\n",
    "df2['data_short'] = pd.to_datetime('01.' + df2['data_short'], format='%d.%m.%Y')\n",
    "# Создаем столбец 'month'\n",
    "df2['month'] = df2['data_short'].dt.month\n",
    "\n",
    "# Создаем столбец 'year'\n",
    "df2['year'] = df2['data_short'].dt.year\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['es_code_int'] = df.apply(get_type_of_es, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_address(df, 'address_raw', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_short']=df['data_short'].astype(str)\n",
    "df['data_short'] = pd.to_datetime('01.' + df['data_short'], format='%d.%m.%Y')\n",
    "# Создаем столбец 'month'\n",
    "df['month'] = df['data_short'].dt.month\n",
    "\n",
    "# Создаем столбец 'year'\n",
    "df['year'] = df['data_short'].dt.year\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df['address_raw'])&set(df2['address_raw']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['index_save'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем метод merge для объединения DataFrame на основе условия\n",
    "df3 = df2[['address_raw', 'es_code_int','month','cost']].copy()\n",
    "df3 = df3.groupby(['address_raw', 'es_code_int','month'], as_index=False)['cost'].mean()\n",
    "merged_df = pd.merge(df, df3, on=['address_raw', 'es_code_int','month'], how='left', suffixes=('', '_prev_year'))\n",
    "\n",
    "# В результате получаем новый DataFrame с добавленными данными\n",
    "print(df.shape, df2.shape)\n",
    "print(merged_df.columns, '\\n',merged_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_merged_df = merged_df[merged_df['cost_prev_year'].isna()]\n",
    "nan_rows_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df.dropna(subset=['cost_prev_year'])\n",
    "merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_merged_df.drop(columns=['cost_prev_year'], inplace=True)\n",
    "shift_value = 1\n",
    "nan_rows_merged_df['month'] = (nan_rows_merged_df['month'] + shift_value - 1) % 12 + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем метод merge для объединения DataFrame на основе условия\n",
    "df3 = df2[['address_raw', 'es_code_int','month','cost']].copy()\n",
    "df3 = df3.groupby(['address_raw', 'es_code_int','month'], as_index=False)['cost'].mean()\n",
    "merged_df2 = pd.merge(nan_rows_merged_df, df3, on=['address_raw', 'es_code_int','month'], how='left', suffixes=('', '_prev_year'))\n",
    "\n",
    "# В результате получаем новый DataFrame с добавленными данными\n",
    "print(nan_rows_merged_df.shape, df2.shape)\n",
    "print(merged_df2.columns, '\\n',merged_df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_merged_df2 = merged_df2[merged_df2['cost_prev_year'].isna()]\n",
    "nan_rows_merged_df2.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df2 = merged_df2.dropna(subset=['cost_prev_year'])\n",
    "merged_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_merged_df2.drop(columns=['cost_prev_year'], inplace=True)\n",
    "shift_value = -2\n",
    "nan_rows_merged_df2['month'] = (nan_rows_merged_df2['month'] + shift_value - 1) % 12 + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем метод merge для объединения DataFrame на основе условия\n",
    "df3 = df2[['address_raw', 'es_code_int','month','cost']].copy()\n",
    "df3 = df3.groupby(['address_raw', 'es_code_int','month'], as_index=False)['cost'].mean()\n",
    "merged_df3 = pd.merge(nan_rows_merged_df2, df3, on=['address_raw', 'es_code_int','month'], how='left', suffixes=('', '_prev_year'))\n",
    "\n",
    "# В результате получаем новый DataFrame с добавленными данными\n",
    "print(nan_rows_merged_df2.shape, df3.shape)\n",
    "print(merged_df3.columns, '\\n',merged_df3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_merged_df3 = merged_df3[merged_df3['cost_prev_year'].isna()]\n",
    "nan_rows_merged_df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df3 = merged_df3.dropna(subset=['cost_prev_year'])\n",
    "merged_df3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fill NaN by adress similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row1 in nan_rows_merged_df3.iterrows():\n",
    "    matching_rows_df2 = df2[(df2['month'] == row1['month']) & (df2['es_code_int'] == row1['es_code_int'])]\n",
    "\n",
    "    best_match_index = -1\n",
    "    best_score = -1\n",
    "\n",
    "    for j, row2 in matching_rows_df2.iterrows():\n",
    "        score = spec_match(str(row1['test']), str(row2['test']))\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_match_index = j\n",
    "\n",
    "    if best_match_index != -1:\n",
    "        nan_rows_merged_df3.at[i, 'prev_year_cost'] = df2.at[best_match_index, 'cost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows_merged_df3['cost_prev_year'] = nan_rows_merged_df3['cost_prev_year'].fillna(nan_rows_merged_df3['prev_year_cost'])\n",
    "nan_rows_merged_df3.drop(columns=['prev_year_cost'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mrg_df не содержит Nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_df = pd.concat([merged_df, merged_df2, merged_df3, nan_rows_merged_df3], ignore_index=True)\n",
    "mrg_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### сейчас добавми дополнительные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_info_file = './data3/qart/merget_tr_q2y_2018.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df = pd.read_excel(add_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['TR_object_name', 'TR_planned_cost', 'TR_cost']\n",
    "\n",
    "# Заполняем пропущенные значения в выбранных колонках нулями\n",
    "add_df[selected_columns] = add_df[selected_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_df_bkp = mrg_df.copy()\n",
    "add_df_bkp = add_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_copy = ['com_sq_estate_q1',\n",
    "       'com_sq_building_q1', 'busy_cb_1_q1', 'not_busy_cb_1_q1',\n",
    "       'rent_out_1_q1', 'rented_1_q1', 'rent_out_sub_1_q1', 'transfer_1_q1',\n",
    "       'transfer_2_q1', 'busy_cb_2_q1', 'not_busy_cb_2_q1', 'rent_out_2_q1',\n",
    "       'rented_2_q1', 'rent_out_sub_2_q1', 'transfer_3_q1', 'transfer_4_q1',\n",
    "       'balance_cost_q1', 'over_price_q1', 'accrual_amount_q1',\n",
    "       'residual_value_q1', 'technical_condition_q1', 'otdel',\n",
    "       'years_holding_q1', 'years_before_q1', 'com_sq_estate_q2',\n",
    "       'com_sq_building_q2', 'busy_cb_1_q2', 'not_busy_cb_1_q2',\n",
    "       'rent_out_1_q2', 'rented_1_q2', 'rent_out_sub_1_q2', 'transfer_1_q2',\n",
    "       'transfer_2_q2', 'busy_cb_2_q2', 'not_busy_cb_2_q2', 'rent_out_2_q2',\n",
    "       'rented_2_q2', 'rent_out_sub_2_q2', 'transfer_3_q2', 'transfer_4_q2',\n",
    "       'balance_cost_q2', 'over_price_q2', 'accrual_amount_q2',\n",
    "       'residual_value_q2', 'technical_condition_q2', 'years_holding_q2',\n",
    "       'years_before_q2', 'com_sq_estate_q3', 'com_sq_building_q3',\n",
    "       'busy_cb_1_q3', 'not_busy_cb_1_q3', 'rent_out_1_q3', 'rented_1_q3',\n",
    "       'rent_out_sub_1_q3', 'transfer_1_q3', 'transfer_2_q3', 'busy_cb_2_q3',\n",
    "       'not_busy_cb_2_q3', 'rent_out_2_q3', 'rented_2_q3', 'rent_out_sub_2_q3',\n",
    "       'transfer_3_q3', 'transfer_4_q3', 'balance_cost_q3', 'over_price_q3',\n",
    "       'accrual_amount_q3', 'residual_value_q3', 'technical_condition_q3',\n",
    "       'years_holding_q3', 'years_before_q3', 'com_sq_estate_q4',\n",
    "       'com_sq_building_q4', 'busy_cb_1_q4', 'not_busy_cb_1_q4',\n",
    "       'rent_out_1_q4', 'rented_1_q4', 'rent_out_sub_1_q4', 'transfer_1_q4',\n",
    "       'transfer_2_q4', 'busy_cb_2_q4', 'not_busy_cb_2_q4', 'rent_out_2_q4',\n",
    "       'rented_2_q4', 'rent_out_sub_2_q4', 'transfer_3_q4', 'transfer_4_q4',\n",
    "       'balance_cost_q4', 'over_price_q4', 'accrual_amount_q4',\n",
    "       'residual_value_q4', 'technical_condition_q4', 'years_holding_q4',\n",
    "       'years_before_q4', 'TR_object_name', 'TR_planned_cost',\n",
    "       'TR_cost'] #without 'address_new' 'cad_code', 'build_date', 'balance_accept_date'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_df.loc[:, cols_to_copy] = None\n",
    "\n",
    "# Создание матрицы оценок совпадения\n",
    "scores_matrix = pd.DataFrame(index=mrg_df.index, columns=add_df.index)\n",
    "\n",
    "for i, row1 in mrg_df.iterrows():\n",
    "    for j, row2 in add_df.iterrows():\n",
    "        scores_matrix.at[i, j] = spec_match(str(row1['test']), str(row2['address_new']))\n",
    "\n",
    "# Получение индексов максимальных значений для каждой строки\n",
    "best_matches_indices = scores_matrix.idxmax(axis=1)\n",
    "\n",
    "# Заполнение колонок в df1\n",
    "for i, column in enumerate(cols_to_copy):\n",
    "    mrg_df[column] = add_df.loc[best_matches_indices, column].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrg_df.to_excel('./data/dataset2018-2019.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mrg_df.isna().value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
